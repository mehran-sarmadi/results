{
  "dataset_revision": "92ba517dfd22f6334111ad84154d16a2890f5b1d",
  "task_name": "PersianFoodSentimentClassification",
  "mteb_version": "1.34.14",
  "scores": {
    "validation": [
      {
        "accuracy": 0.835742,
        "f1": 0.834822,
        "f1_weighted": 0.834822,
        "ap": 0.798977,
        "ap_weighted": 0.798977,
        "scores_per_experiment": [
          {
            "accuracy": 0.839844,
            "f1": 0.83794,
            "f1_weighted": 0.83794,
            "ap": 0.817385,
            "ap_weighted": 0.817385
          },
          {
            "accuracy": 0.830078,
            "f1": 0.827672,
            "f1_weighted": 0.827672,
            "ap": 0.807707,
            "ap_weighted": 0.807707
          },
          {
            "accuracy": 0.856934,
            "f1": 0.856291,
            "f1_weighted": 0.856291,
            "ap": 0.825546,
            "ap_weighted": 0.825546
          },
          {
            "accuracy": 0.845703,
            "f1": 0.84502,
            "f1_weighted": 0.84502,
            "ap": 0.810666,
            "ap_weighted": 0.810666
          },
          {
            "accuracy": 0.837891,
            "f1": 0.836513,
            "f1_weighted": 0.836513,
            "ap": 0.80879,
            "ap_weighted": 0.80879
          },
          {
            "accuracy": 0.854004,
            "f1": 0.853526,
            "f1_weighted": 0.853526,
            "ap": 0.818486,
            "ap_weighted": 0.818486
          },
          {
            "accuracy": 0.841797,
            "f1": 0.840874,
            "f1_weighted": 0.840874,
            "ap": 0.80872,
            "ap_weighted": 0.80872
          },
          {
            "accuracy": 0.840332,
            "f1": 0.839614,
            "f1_weighted": 0.839614,
            "ap": 0.803882,
            "ap_weighted": 0.803882
          },
          {
            "accuracy": 0.798828,
            "f1": 0.798759,
            "f1_weighted": 0.798759,
            "ap": 0.735517,
            "ap_weighted": 0.735517
          },
          {
            "accuracy": 0.812012,
            "f1": 0.812011,
            "f1_weighted": 0.812011,
            "ap": 0.753073,
            "ap_weighted": 0.753073
          }
        ],
        "main_score": 0.835742,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.840625,
        "f1": 0.839722,
        "f1_weighted": 0.839722,
        "ap": 0.805351,
        "ap_weighted": 0.805351,
        "scores_per_experiment": [
          {
            "accuracy": 0.840332,
            "f1": 0.838165,
            "f1_weighted": 0.838165,
            "ap": 0.820872,
            "ap_weighted": 0.820872
          },
          {
            "accuracy": 0.828613,
            "f1": 0.826287,
            "f1_weighted": 0.826287,
            "ap": 0.804813,
            "ap_weighted": 0.804813
          },
          {
            "accuracy": 0.862793,
            "f1": 0.86214,
            "f1_weighted": 0.86214,
            "ap": 0.834032,
            "ap_weighted": 0.834032
          },
          {
            "accuracy": 0.842773,
            "f1": 0.842319,
            "f1_weighted": 0.842319,
            "ap": 0.803021,
            "ap_weighted": 0.803021
          },
          {
            "accuracy": 0.848633,
            "f1": 0.847291,
            "f1_weighted": 0.847291,
            "ap": 0.82391,
            "ap_weighted": 0.82391
          },
          {
            "accuracy": 0.861816,
            "f1": 0.861364,
            "f1_weighted": 0.861364,
            "ap": 0.828706,
            "ap_weighted": 0.828706
          },
          {
            "accuracy": 0.849609,
            "f1": 0.848732,
            "f1_weighted": 0.848732,
            "ap": 0.818998,
            "ap_weighted": 0.818998
          },
          {
            "accuracy": 0.853027,
            "f1": 0.852307,
            "f1_weighted": 0.852307,
            "ap": 0.821371,
            "ap_weighted": 0.821371
          },
          {
            "accuracy": 0.79541,
            "f1": 0.79538,
            "f1_weighted": 0.79538,
            "ap": 0.732892,
            "ap_weighted": 0.732892
          },
          {
            "accuracy": 0.823242,
            "f1": 0.823236,
            "f1_weighted": 0.823236,
            "ap": 0.764896,
            "ap_weighted": 0.764896
          }
        ],
        "main_score": 0.840625,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 22.197794198989868,
  "kg_co2_emissions": null
}