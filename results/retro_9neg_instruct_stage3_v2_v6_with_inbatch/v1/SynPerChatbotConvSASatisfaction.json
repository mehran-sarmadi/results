{
  "dataset_revision": "50fd9d5d09edd53af89af765636be5db6f983f0e",
  "task_name": "SynPerChatbotConvSASatisfaction",
  "mteb_version": "1.34.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.934499,
        "f1": 0.928097,
        "f1_weighted": 0.933945,
        "ap": 0.922101,
        "ap_weighted": 0.922101,
        "scores_per_experiment": [
          {
            "accuracy": 0.941725,
            "f1": 0.935631,
            "f1_weighted": 0.941032,
            "ap": 0.925167,
            "ap_weighted": 0.925167
          },
          {
            "accuracy": 0.932401,
            "f1": 0.926453,
            "f1_weighted": 0.932157,
            "ap": 0.925553,
            "ap_weighted": 0.925553
          },
          {
            "accuracy": 0.939394,
            "f1": 0.933966,
            "f1_weighted": 0.939129,
            "ap": 0.931433,
            "ap_weighted": 0.931433
          },
          {
            "accuracy": 0.925408,
            "f1": 0.918961,
            "f1_weighted": 0.925195,
            "ap": 0.919702,
            "ap_weighted": 0.919702
          },
          {
            "accuracy": 0.939394,
            "f1": 0.933162,
            "f1_weighted": 0.938728,
            "ap": 0.923853,
            "ap_weighted": 0.923853
          },
          {
            "accuracy": 0.93007,
            "f1": 0.922879,
            "f1_weighted": 0.929301,
            "ap": 0.914935,
            "ap_weighted": 0.914935
          },
          {
            "accuracy": 0.927739,
            "f1": 0.920182,
            "f1_weighted": 0.92688,
            "ap": 0.911823,
            "ap_weighted": 0.911823
          },
          {
            "accuracy": 0.948718,
            "f1": 0.943792,
            "f1_weighted": 0.94833,
            "ap": 0.936713,
            "ap_weighted": 0.936713
          },
          {
            "accuracy": 0.923077,
            "f1": 0.915033,
            "f1_weighted": 0.922163,
            "ap": 0.907426,
            "ap_weighted": 0.907426
          },
          {
            "accuracy": 0.937063,
            "f1": 0.930913,
            "f1_weighted": 0.936534,
            "ap": 0.924403,
            "ap_weighted": 0.924403
          }
        ],
        "main_score": 0.934499,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 13.05142855644226,
  "kg_co2_emissions": null
}