{
  "dataset_revision": "92ba517dfd22f6334111ad84154d16a2890f5b1d",
  "task_name": "PersianFoodSentimentClassification",
  "mteb_version": "1.34.14",
  "scores": {
    "validation": [
      {
        "accuracy": 0.751367,
        "f1": 0.747958,
        "f1_weighted": 0.747958,
        "ap": 0.698018,
        "ap_weighted": 0.698018,
        "scores_per_experiment": [
          {
            "accuracy": 0.793457,
            "f1": 0.79214,
            "f1_weighted": 0.79214,
            "ap": 0.749149,
            "ap_weighted": 0.749149
          },
          {
            "accuracy": 0.70166,
            "f1": 0.690254,
            "f1_weighted": 0.690254,
            "ap": 0.666825,
            "ap_weighted": 0.666825
          },
          {
            "accuracy": 0.79834,
            "f1": 0.798339,
            "f1_weighted": 0.798339,
            "ap": 0.738438,
            "ap_weighted": 0.738438
          },
          {
            "accuracy": 0.771484,
            "f1": 0.767799,
            "f1_weighted": 0.767799,
            "ap": 0.73427,
            "ap_weighted": 0.73427
          },
          {
            "accuracy": 0.756348,
            "f1": 0.753153,
            "f1_weighted": 0.753153,
            "ap": 0.713245,
            "ap_weighted": 0.713245
          },
          {
            "accuracy": 0.771973,
            "f1": 0.77189,
            "f1_weighted": 0.77189,
            "ap": 0.712884,
            "ap_weighted": 0.712884
          },
          {
            "accuracy": 0.76416,
            "f1": 0.763361,
            "f1_weighted": 0.763361,
            "ap": 0.711036,
            "ap_weighted": 0.711036
          },
          {
            "accuracy": 0.757324,
            "f1": 0.757032,
            "f1_weighted": 0.757032,
            "ap": 0.690584,
            "ap_weighted": 0.690584
          },
          {
            "accuracy": 0.711914,
            "f1": 0.710189,
            "f1_weighted": 0.710189,
            "ap": 0.644862,
            "ap_weighted": 0.644862
          },
          {
            "accuracy": 0.687012,
            "f1": 0.675422,
            "f1_weighted": 0.675422,
            "ap": 0.618887,
            "ap_weighted": 0.618887
          }
        ],
        "main_score": 0.751367,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.743311,
        "f1": 0.739705,
        "f1_weighted": 0.739705,
        "ap": 0.690217,
        "ap_weighted": 0.690217,
        "scores_per_experiment": [
          {
            "accuracy": 0.788086,
            "f1": 0.786785,
            "f1_weighted": 0.786785,
            "ap": 0.742406,
            "ap_weighted": 0.742406
          },
          {
            "accuracy": 0.695312,
            "f1": 0.683478,
            "f1_weighted": 0.683478,
            "ap": 0.659858,
            "ap_weighted": 0.659858
          },
          {
            "accuracy": 0.791504,
            "f1": 0.7915,
            "f1_weighted": 0.7915,
            "ap": 0.729986,
            "ap_weighted": 0.729986
          },
          {
            "accuracy": 0.768066,
            "f1": 0.764755,
            "f1_weighted": 0.764755,
            "ap": 0.728251,
            "ap_weighted": 0.728251
          },
          {
            "accuracy": 0.745605,
            "f1": 0.740653,
            "f1_weighted": 0.740653,
            "ap": 0.706163,
            "ap_weighted": 0.706163
          },
          {
            "accuracy": 0.770508,
            "f1": 0.770382,
            "f1_weighted": 0.770382,
            "ap": 0.712027,
            "ap_weighted": 0.712027
          },
          {
            "accuracy": 0.732422,
            "f1": 0.731129,
            "f1_weighted": 0.731129,
            "ap": 0.678928,
            "ap_weighted": 0.678928
          },
          {
            "accuracy": 0.752441,
            "f1": 0.752398,
            "f1_weighted": 0.752398,
            "ap": 0.68831,
            "ap_weighted": 0.68831
          },
          {
            "accuracy": 0.709961,
            "f1": 0.708268,
            "f1_weighted": 0.708268,
            "ap": 0.643236,
            "ap_weighted": 0.643236
          },
          {
            "accuracy": 0.679199,
            "f1": 0.667699,
            "f1_weighted": 0.667699,
            "ap": 0.613004,
            "ap_weighted": 0.613004
          }
        ],
        "main_score": 0.743311,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 24.399648666381836,
  "kg_co2_emissions": null
}